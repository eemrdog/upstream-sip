# Default values for eric-bss-ecmeoc-common.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: nginx
  tag: stable
  pullPolicy: IfNotPresent

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []

  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}

iamAuth:
  multitenancy: false
  superUserOrganizationName: "Ericsson"
  superUserOrganizationId: "eeeeeeee-117e-11ec-82a8-0242ac130003"
  superUserPrivilegeName: "EriSuperUserPriv"

credentials:
  dced:
    password: "password"
  cm:
    db:
      user: pguser
      pwd: pgpwd
  alarm:
    db:
      user: pguser
      pwd: pgpwd
  iam:
    db:
      user: pguser
      pwd: pgpwd
    kcadminid: admin
    kcpasswd: kcpw
  nels:
    db:
      user: lmuser
      pwd: lmpwd
  notification:
    db:
      user: pguser
      pwd: pgpwd

eric-data-distributed-coordinator-ed:
  enabled: true
  pods:
    etcd:
      replicas: 2
  updateStrategy:
    type: RollingUpdate
  imageCredentials: # Updated added
    dced: # Updated added
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        imagePullPolicy: IfNotPresent # Updated added
      repoPath: "eocecm22" # Updated added
    brAgent: # Updated added
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        imagePullPolicy: IfNotPresent # Updated added
      repoPath: "eocecm22" # Updated added
    pullSecret: scmcred # Updated added
    logshipper: # Updated added
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        imagePullPolicy: IfNotPresent # Updated added
      repoPath: "eocecm22" # Updated added                                                                                     
  brAgent:
   properties:
     applicationProperties: |-
       dced.agent.restore.type=overwrite
       dced.excluded.paths=/shelter,/kms/core/lock
  resources:
    init:
      requests:
        cpu: "200m"
        memory: "200Mi"
      limits:
        cpu: "500m"
        memory: "500Mi"
    dced:
      requests:
        # This is the min CPU setting at startup
        cpu: "400m"
        # This is the min Memory setting at startup
        memory: "400Mi"
      limits:
        # This the maximum cpu setting that can be requested
        cpu: "1"
        # This is the max memory setting that can be requested
        memory: "1Gi"
    brAgent:
      requests:
        cpu: "400m"
        memory: "400Mi"
      limits:
        cpu: "1"
        memory: "2Gi"
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
    metricsexporter:
      requests:
        cpu: "100m"
        memory: "8Mi"
      limits:
        cpu: "200m"
        memory: "32Mi"
  security:
    etcd:
      certificates:
        enabled: true
  persistence:
    persistentVolumeClaim:
      size: "1Gi"
      storageClassName: gp2

eric-sec-key-management:
  enabled: true
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  imageCredentials:
    repoPath: eocecm22 # Updated added
    pullSecret: scmcred # Updated added
    pullPolicy: IfNotPresent
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
      imagePullPolicy: IfNotPresent # Updated added
    logshipper: # Updated added
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        imagePullPolicy: IfNotPresent # Updated added
      repoPath: eocecm22 # Updated added
  persistence:
    type: etcd
    etcd:
      tls:
        enabled: true
  ## Shelter is the feature that provides the non-backed up Vault instance
  shelter:
    enabled: true
  service:
    tls:
      enabled: true
  resources:
    vault:
      requests:
        cpu: "100m"
        memory: "400Mi"
      limits:
        cpu: "300m"
        memory: "1200Mi"

eric-sec-sip-tls-crd:
  enabled: false

eric-sec-sip-tls:
  enabled: true
  updateStrategy:
    type: RollingUpdate
  imageCredentials:
    ## pullSecret, the secret resource name used for authenticating towards docker registry where images are pulled
    ## overrides the global value when set
    pullSecret: scmcred
    sip:
      repoPath: eocecm22
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        pullSecret: scmcred # Updated added
        imagePullPolicy: IfNotPresent # Updated added
    init:
      repoPath: eocecm22
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        pullSecret: scmcred # Updated added
        imagePullPolicy: IfNotPresent # Updated added
    supervisor:
      repoPath: eocecm22
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        pullSecret: scmcred # Updated added
        imagePullPolicy: IfNotPresent # Updated added
    ## settings for logshipper sidecar
    logshipper:
      repoPath: eocecm22
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        pullSecret: scmcred # Updated added
        imagePullPolicy: IfNotPresent # Updated added

  logLevel: info
  keyManagement:
    hostname: eric-sec-key-management
    port: 8210
  etcd:
    hostname: #eric-data-distributed-coordinator-ed
  kafka:
    hostname: eric-data-message-bus-kf
  resources:
    sip-tls:
      requests:
        memory: "200Mi"
        cpu: "100m"
      limits:
        memory: "400Mi"
        cpu: "3000m"
    sip-tls-supervisor:
      requests:
        memory: "200Mi"
        cpu: "100m"
      limits:
        memory: "400Mi"
        cpu: "3000m"
    sip-tls-init:
      requests:
        memory: "200Mi"
        cpu: "100m"
      limits:
        memory: "400Mi"
        cpu: "3000m"
    logshipper:
      requests:
        memory: "80Mi"
        cpu: "80m"
      limits:
        memory: "100Mi"
        cpu: "100m"

eric-log-shipper:
  enabled: false
  imageCredentials: # Updated added
    repoPath: eocecm22 # Updated added
    registry: # Updated added
      imagePullPolicy: IfNotPresent # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 25%
    type: RollingUpdate
  logLevel: "error"
  security:
    tls:
      logtransformer:
        enabled: true
  logshipper:
    # consoleOutput: false - removed
    cfgData: ""
#    cfgData: |
#      paths:
#        - /var/lib/docker/containers/**/*.log
#        - /var/log/pods/**/*.log
#      fields:
#        facility: "log audit"

    autodiscover:
      enabled: true
      namespace: ".RELEASE.NAMESPACE"
      logplane: kubelog
      json:
        enabled: true
        target: json
      hints:
        enabled: true
      inclusions:
      exclusions:
      - field: "kubernets.labels.app.kubernetes.io/name"
        value: "eric-log-shipper"
#      paths:
#        - /var/log/pods/${data.kubernetes.container.id}/*-json.log
#        - /var/log/pods/${data.kubernetes.namespace}_${data.kubernetes.pod.name}_${data.kubernetes.pod.uid}/${data.kubernetes.container.name}/*.log
      templates:
        - condition:
            equals:
                  kubernetes.container.runtime: containerd
          config:
            - type: log
              paths:
                - /var/log/pods/*_${data.kubernetes.pod.uid}/${data.kubernetes.container.name}/*.log
#            - type: docker
#              containers:
#                ids:
#                  - "${data.kubernetes.container.id}"
#      providers:
#        - type: docker
#          templates:
        - condition.contains:
            kubernetes.container.image: wildfly
          config:
            - type: log
              paths:
                - /var/log/*/*/security/${data.kubernetes.pod.name}/*AuditTrail.log
              fields:
                facility: "log audit"
        - condition.or:
            - contains:
                kubernetes.container.image: shoppingcart
            - contains:
                kubernetes.container.image: pobrowsing
            - contains:
                kubernetes.container.image: jxc
            - contains:
                kubernetes.container.image: technicalbrowsing
            - contains:
                kubernetes.container.image: som
            - contains:
                kubernetes.container.image: process-controller
            - contains:
                kubernetes.container.image: plm
          config:
            - type: log
              paths:
                - /var/log/*/*/security/${data.kubernetes.pod.name}/*security.log
              fields:
                facility: "log audit"
    harvester:
      closeTimeout: "0"
      logData:
        - format: json
  resources:
    logshipper:
      requests:
        cpu: "100m"
        memory: "100Mi"
      limits:
        cpu: "250m"
        memory: "500Mi"
  rbac:
    automountServiceAccountToken: true
    createClusterRole: false
    createClusterRoleBinding: false # must be the same as for createClusterRole

  additionalVolumes: |
    - name: docker-containers
      hostPath:
        path: /var/lib/docker/containers
    - name: kubernetes-containers
      hostPath:
        path: /var/log

  additionalVolumeMounts: |
    - name: docker-containers
      mountPath: /var/lib/docker/containers
      readOnly: true
    - name: kubernetes-containers
      mountPath: /var/log
      readOnly: true


eric-log-transformer:
  enabled: false
  replicaCount: 1
  updateStrategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  imageCredentials:
    repoPath: eocecm22 # Updated added
    registry: # Updated added
      imagePullPolicy: IfNotPresent # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
  searchengine:
    host: eric-data-search-engine
    logplaneConfig:
    - field: "[extra_data][asi][log_plane]"
      value: "alarm"
      newLogplane: "adp-app-asi-logs"
    - field: "[facility]"
      value: "log audit"
      newLogplane: "adp-app-audit-logs"
    - field: "[metadata][category]"
      contains: "-privacy-"
      newLogplane: "adp-app-audit-logs"
    exclusion:
    - logplane:
      rules:
        - field:
          value:
  jvmHeap: 1024m
  resources:
    logtransformer:
      requests:
        cpu: 250m
        memory: 2Gi
      limits:
        cpu: 1000m
        memory: 2Gi
    metrics:
      limits:
        cpu: "100m"
        memory: "256Mi"
      requests:
        cpu: "25m"
        memory: "64Mi"
    tlsproxy:
      limits:
        cpu: "100m"
        memory: "128Mi"
      requests:
        cpu: "25m"
        memory: "64Mi"
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
  logLevel: "error"
  metrics:
    enabled: true
    httpPort: 9114
  config:
    adpJson:
      validation:
        enabled: false
      transformation:
        enabled: true
      # Do not add quotes around the field name
      decodedAdpJsonField: json
    filebeat:
      input:
        beats:
          client_inactivity_timeout: 120
    fileOutput: false
    filter: |
        if [type] == "filebeat" {
          json {
            source => "message"
          }
          # cassandra
          grok {
            match => { "log" => "%{WORD:logType}\s\s\[%{NOTSPACE:thread}\]\s%{TIMESTAMP_ISO8601:logDate}\s%{NOTSPACE:service}\s\-\s%{GREEDYDATA:msgBody}" }
          }
          # CPR Application
          grok {
            match => { "log" => "%{TIMESTAMP_ISO8601:logDate}\s\[%{WORD:logType}?\]\s\[%{WORD:logLevel}?\]\s\[%{NOTSPACE:hostName}?\]\s\[%{NOTSPACE:applicationName}\]\s\[%{NOTSPACE:executionId}?\]\s\[%{NOTSPACE:correlationId}?\]\s\s\[%{NOTSPACE:thread}?\]\s\[%{GREEDYDATA:className}?\]\s%{GREEDYDATA:msgBody}" }
          }
          # Application-Audit-log
          grok {
            match => { "log" => "%{TIMESTAMP_ISO8601:logDate}\s\[%{WORD:logType}?\]\s\[%{WORD:logLevel}?\]\s\[%{NOTSPACE:hostName}?\]\s\[%{NOTSPACE:applicationName}\]\s\[%{NOTSPACE:executionId}?\]\s\[%{NOTSPACE:correlationId}?\]\s\[%{NOTSPACE:partyid}?\]\s\[%{NOTSPACE:userrole}?\]\s\s\[%{NOTSPACE:thread}?\]\s\[%{GREEDYDATA:className}?\]\s%{GREEDYDATA:msgBody}" }
          }
          # camunda
          grok {
            match => { "log" => "%{TIMESTAMP_ISO8601:logDate}\s%{WORD:logType}?\s\s\s\s\[%{WORD:thread}?\]\s\[%{NOTSPACE:applicationName}?\]\s%{GREEDYDATA:msgBody}" }
          }
          # cm-mediator
          grok {
            match => { "log" => "%{TIMESTAMP_ISO8601:logDate}\s%{NOTSPACE:hostName}\s%{WORD:logType}\s%{GREEDYDATA:msgBody}" }
          }
          # PG
          grok {
            match => { "log" => "%{TIMESTAMP_ISO8601:logDate}.*\:\s\s%{GREEDYDATA:msgBody}" }
          }
          # Wildfly Application
          grok {
            match => { "log" => "%{TIMESTAMP_ISO8601:logDate}\s%{WORD:logLevel}?\s\[%{NOTSPACE:thread}\]\s\(%{GREEDYDATA:className}?\)\s%{GREEDYDATA:msgBody}" }
          }
          # ECM/EOC Application
          grok {
            match => { "log" => "%{TIMESTAMP_ISO8601:logDate}\s%{WORD:logLevel}?\s\[%{WORD:logType}\]?\s\(%{NOTSPACE:className}\)\s%{TIMESTAMP_ISO8601:logDate}\s\[%{GREEDYDATA:thread}?\]\s%{GREEDYDATA:msgBody}" }
          }
          # OSGi Application 1
          grok {
            match => { "log" => "%{TIMESTAMP_ISO8601:logDate}\s?\s%{WORD:logLevel}\s?\s%{GREEDYDATA:thread}\s?\s%{NOTSPACE:applicaionName}\s?\s%{NOTSPACE:class}\s%{NOTSPACE:classid}\s?\s%{NOTSPACE:bundleid}\s?\s%{NOTSPACE:bundlename}\s?\s%{NOTSPACE:bundleversion}\s?\s%{GREEDYDATA:msgBody}" }
          }
          # OSGI Security Logs
          grok {
            match => { "log" => "%{WORD:contextName}\s?\s%{TIMESTAMP_ISO8601:logDate}\s?\s%{WORD:logLevel}\s?\s%{GREEDYDATA:thread}\s?\s%{NOTSPACE:class}\s%{NOTSPACE:classid}\s?\s%{GREEDYDATA:msgBody}" }
          }
        }
    input:
    output:
  security:
    tls:
      logshipper:
        enabled: true
#  uncomment to enable audit logs streaming to external system
#  syslog:
#    defaultFacility: 1
#    defaultSeverity: 5
#    syslogLogplane: auditlog
#    outputs:
#      - host: "externalhostname"
#        port: 514
#    inclusion:
#      - field: "[facility]"
#        value: "log audit"
#  networkPolicy:
#    egress:
#      - cidr: 172.17.0.0/32
#        ports:
#        - protocol: TCP
#          port: 514

eric-data-search-engine:
  enabled: false
  autoSetRequiredWorkerNodeSysctl: true
  imageCredentials:
    pullPolicy: IfNotPresent
    repoPath: eocecm22 # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
  updateStrategy:
    ingest:
      type: "RollingUpdate"
      rollingUpdate:
        maxSurge: 2
        maxUnavailable: 0
    master:
      type: "RollingUpdate"
      rollingUpdate:
        maxSurge: 4
        maxUnavailable: 1
    data:
      type: "RollingUpdate"
      rollingUpdate:
        partition: 0
    bragent:
      type: "RollingUpdate"
  replicaCount:
    ingest: 1
    master: 3
    data: 2
  metrics:
    enabled: true
  jvmHeap:
    ingest: "512m"
    master: "512m"
    data: "1024m"
  service:
    name: "eric-data-search-engine"
    network:
      protocol:
        IPv6: false
    endpoints:
      internode:
        tls:
          verifyClientHostname: false
      rest:
        tls:
          enforced: required
          verifyClientCertificate: optional
          verifyClientHostname: false
  resources:
    ingest:
      limits:
        cpu: "500m"
        memory: "1Gi"
      requests:
        cpu: "500m"
        memory: "1Gi"
    master:
      limits:
        cpu: "500m"
        memory: "1Gi"
      requests:
        cpu: "500m"
        memory: "1Gi"
    data:
      limits:
        cpu: "500m"
        memory: "2Gi"
      requests:
        cpu: "500m"
        memory: "2Gi"
    bragent:
      limits:
        cpu: "500m"
        memory: "1Gi"
      requests:
        cpu: "500m"
        memory: "1Gi"
    metrics:
      limits:
        cpu: "100m"
        memory: "128Mi"
      requests:
        cpu: "25m"
        memory: "64Mi"
    tlsproxy:
      limits:
        cpu: "100m"
        memory: "128Mi"
      requests:
        cpu: "25m"
        memory: "64Mi"
    logshipper:
      limits:
        memory: "100Mi"
        cpu: "100m"
      requests:
        memory: "50Mi"
        cpu: "50m"
    sysctl:
      limits:
        cpu: "100m"
        memory: "128Mi"
      requests:
        cpu: "25m"
        memory: "64Mi"
    chmod:
      limits:
        cpu: "100m"
        memory: "128Mi"
      requests:
        cpu: "25m"
        memory: "64Mi"
    preupgradehook:
      limits:
        cpu: "100m"
        memory: "128Mi"
      requests:
        cpu: "25m"
        memory: "64Mi"
  persistence:
    data:
      persistentVolumeClaim:
        size: "1Gi"
        storageClassName: gp2
    backup:
      persistentVolumeClaim:
        size: "1Gi"
        storageClassName: gp2
    master:
      persistentVolumeClaim:
        size: "64Mi"
        storageClassName: gp2

eric-data-search-engine-curator:
  enabled: false
  imageCredentials: # Updated added
    repoPath: eocecm22 # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
  cronjob:
    curator:
      enabled: true
      schedule: "0 1 * * *"
      successfulJobHistoryLimit: 1
      failedJobHistoryLimit: 3
  actions: |
    1:
      action: delete_indices
      description: Remove logs older than 5 days
      options:
        disable_action: false
        ignore_empty_list: true
      filters:
      - filtertype: age
        source: name
        direction: older
        timestring: '%Y.%m.%d'
        unit: days
        unit_count: 5

eric-data-coordinator-zk:
  enabled: true
  replicas: 2
  updateStrategy:
    type: "RollingUpdate"
  minAvailable: "55%"
  imageCredentials: # Updated added
    datacoordinatorzk: # Updated added
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        imagePullPolicy: IfNotPresent # Updated added
      repoPath: "eocecm22" # Updated added
    brAgent: # Updated added
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        imagePullPolicy: IfNotPresent # Updated added
      repoPath: "eocecm22" # Updated added
    pullSecret: scmcred # Updated added
    logshipper: # Updated added
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        imagePullPolicy: IfNotPresent # Updated added
      repoPath: "eocecm22" # Updated added
  resources:
    datacoordinatorzk:
      requests:
        cpu: "1"
        memory: "2Gi"
      limits:
        cpu: "2"
        memory: "4Gi"
    brAgent:
      requests:
        cpu: "1"
        memory: "1Gi"
      limits:
        cpu: "1"
        memory: "2Gi"
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
    metricsexporter:
      requests:
        cpu: "100m"
        memory: "8Mi"
      limits:
        cpu: "200m"
        memory: "32Mi"
  logLevel: "INFO"
  heap: "256M"
  persistence:
    persistentVolumeClaim:
      size: "5Gi"
      storageClassName: gp2
  security:
    tls:
      agentToBro:
        enabled: true
  livenessProbeInitialDelaySeconds: 75
  livenessProbeTimeoutSeconds: 75

eric-data-message-bus-kf:
  configurationOverrides:
    "num.partitions": "3" # To be tuned based on the throughput
    "min.insync.replicas": "2"
    "num.io.threads": "3"     #Value based on the number of partitions
    "num.network.threads": "3"  #Value based on the number of partitions
    "log.retention.bytes": "1073741824" # To be tuned based on the throughput and disk storage
    "log.segment.bytes": "65536000"
    "log.retention.check.interval.ms": "30000"
    "log.retention.minutes": "1" # To be tuned based on the throughput and disk storage
    "log.retention.ms": "1000" # To be tuned based on the throughput and disk storage
    "file.delete.delay.ms": "10000"
    "log.cleaner.threads": "5" # Value based on the number of io threads
    "log.cleaner.backoff.ms": "1000"
    "log.cleaner.delete.retention.ms": "1000"
    "log.cleaner.enable": "true"
    "log.cleaner.delete.retention.ms": "1000"
    "log.segment.delete.delay.ms": "1000"
  enabled: true #Enable when deploy CPR
  replicas: 2
  updateStrategy:
    type: "RollingUpdate"
  imageCredentials: # Updated added
    messagebuskf: # Updated added
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        imagePullPolicy: IfNotPresent # Updated added
      repoPath: "eocecm22" # Updated added
    pullSecret: scmcred # Updated added
    logshipper: # Updated added
      registry: # Updated added
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
        imagePullPolicy: IfNotPresent # Updated added
      repoPath: "eocecm22" # Updated added
  resources:
    messagebuskf:
      requests:
        cpu: "250m"
        memory: "0.75Gi"
      limits:
        cpu: "500m"
        memory: "1Gi"
    jmxExporter:
      requests:
        cpu: "50m"
        memory: "128Mi"
      limits:
        cpu: "100m"
        memory: "256Mi"
  persistence:
    persistentVolumeClaim:
      enabled: true
      size: "5Gi"
      storageClassName: gp2
  readynessProbeTimeoutSeconds: 10 # default 5 seconds is not enough
  service:
    endpoints:
      messagebuskf:
        sasl:
          enforced: "optional"
        tls:
          enforced: "optional"
          verifyClientCertificate: "optional"
          servcertTimeToLive: 3600
          servcertRenewalLeadTime: 3000
      dataCoordinator:
        tls:
          enforced: "required"
          clientTimeToLive: 3600
          clientRenewalLeadTime: 3000
  security:
    tls:
      messagebuskf:
        provider: "sip-tls"

eric-cm-mediator:
  enabled: true
  global:
    security:
      tls:
        enabled: true
  replicaCount: 2
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 50%
      maxSurge: 50%
  imageCredentials:
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
    repoPath: eocecm22 # Updated added
    pullPolicy: IfNotPresent
  service:
    endpoints:
      restapi:
        tls:
          enforced: optional # Must be optional because CPR does not work with if two ways tls is enforced.
          verifyClientCertificate: optional # Must be optional because CPR does not work with if two ways tls is enforced.
  cmm:
    debug: False
    logLevel: "Info"
    logFormat: "adpjson"
    kafkaLogLevel: "Info"
  backend:
    type: postgres
    hostname: "eric-data-document-database-pg"
    dbname: adp_gs_cm
  kafka:
    hostname: "eric-data-message-bus-kf-client"
  resources:
    eric-cm-mediator:
      requests:
        cpu: "500m"
        memory: "256Mi"
      limits:
        cpu: "2000m"
        memory: "512Mi"
  credentials:
    kubernetesSecretName: "eric-data-document-database-pg-credentials"
    keyForUserId: "cmmUKey"
    keyForUserPw: "cmmPKey"
  cmkey:
    enable: false #CM Key is needed for certificate manager

eric-fh-alarm-handler:
  enabled: false #Enable when deploy CPR
  replicaCount: 1
  global:
    security:
      tls:
        enabled: true
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 50%
      maxSurge: 50%
  alarmhandler:
    debug: false
    configmap:
      faultmappings: "eric-fh-alarm-handler-faultmappings"
    logFormat: "adpjson"
  imageCredentials:
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
      imagePullPolicy: IfNotPresent # Updated added
    repoPath: eocecm22 # Updated added
    kafka:
      registry:
        url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated
        pullSecret: scmcred # Updated
        imagePullPolicy: IfNotPresent # Updated
      repoPath: eocecm22 # Updated
    pullPolicy: IfNotPresent
  backend:
    type: postgres
    hostname: "eric-fm-database-pg"
    dbname: adp_gs_ah
    dbuser: ah
    port: 5432
  cmm:
    hostname: eric-cm-mediator
  dataCoordinator:
    hostname: "eric-data-coordinator-zk"
  kafka:
    hostname: "eric-data-message-bus-kf-client"
  redis:
    hostname: "eric-data-key-value-database-rd-operand"
  resources:
    alarmhandler:
      requests:
        memory: "384Mi"
        cpu: "500m"
        ephemeral-storage: "2Gi"
      limits:
        memory: "512Mi"
        cpu: "1000m"
        ephemeral-storage: "4Gi"
    topiccreator:
      requests:
        memory: "384Mi"
        cpu: "500m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "512Mi"
        cpu: "1000m"
        ephemeral-storage: "2Gi"
    logshipper:
      requests:
        cpu: "20m"
        memory: "50Mi"
      limits:
        cpu: "50m"
        memory: "100Mi"
      disableProbes: false
    ericsecoauthproxy:
      requests:
        memory: 30Mi
        cpu: 10m
      limits:
        memory: 150Mi
        cpu: 50m
    ericsecoauthsap:
      requests:
        memory: 30Mi
        cpu: 10m
      limits:
        memory: 150Mi
        cpu: 50m
  credentials:
    kubernetesSecretName: "eric-data-document-database-pg-credentials"
    keyForUserId: "ahUKey"
    keyForUserPw: "ahPKey"

eric-fh-snmp-alarm-provider:
  enabled: false
  imageCredentials:
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
    repoPath: eocecm22 # Updated added
    pullPolicy: IfNotPresent
  service:
    snmpAgentPort: 1161 # Do not change it to default:161, as it will already be in use.
    replicas: 1 # Scaling not supported
    secretName: "eric-bss-ecmeoc-common-alarm-provider"
  ingress:
    enabled: true
    snmpAgentPort: 161
    hostname: "eric-fh-snmp-alarm-provider"
    tls:
      passthrough: false
  resources:
    alarmprovider:
      requests:
        memory: "384Mi"
        cpu: "0.1"
        ephemeral-storage: 2Gi
      limits:
        memory: "1.5Gi"
        cpu: "0.2"
        ephemeral-storage: 4Gi
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
    vip:
      requests:
        memory: "30Mi"
        cpu: "25m"
        ephemeral-storage: 100Mi
      limits:
        memory: "50Mi"
        cpu: "40m"
        ephemeral-storage: 200Mi
  ah:
    # ah client certificate secret name
    clientCertSecret: eric-sec-snmp-ap-ah-cert
    # AH certificate authority
    caName: eric-fh-alarm-handler-ca
  messageBusKF:
    # messageBusKF client certificate secret name
    clientCertSecret: eric-sec-snmp-ap-message-bus-kf-cert
    # messageBusKF certificate authority
    caName: eric-data-message-bus-kf-client-client-ca

#Override during installation
ahSnmpTrapsConfigMap: |
  {"trapTargets": [{"address":"10.100.110.10","community":"public"}]}

eric-idam-database-pg:
  nameOverride: eric-idam-database-pg
  enabled: true
  brAgent:
    enabled: false
    logLevel: info
    logicalDBBackupEnable: false
    backupTypeList:
      - "idam-data"
  imageCredentials:
    pullPolicy: IfNotPresent
    repoPath: eocecm22 # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
  highAvailability:
    synchronousModeEnabled: true
    replicaCount: 2
  postgresDatabase: "idam"
  credentials:
    kubernetesSecretName: "eric-data-document-database-pg-credentials"
    keyForUserId: "amUKey"
    keyForUserPw: "amPKey"
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
  persistentVolumeClaim:
    storageClassName: gp2
    enabled: true
    size: 2Gi
  patroni:
    logLevel: INFO
  metrics:
    enabled: true
    logLevel: info
    service:
      port: 9187
  resources:
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
    postgres:
      requests:
        memory: "256Mi"
        cpu: "100m"
        hugepages-2Mi:
        hugepages-1Gi:
      limits:
        cpu: "1"
        memory: "2560Mi"
        hugepages-2Mi:
        hugepages-1Gi:
    metrics:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "256Mi"
    kube_client:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "512Mi"
    brm:
      requests:
        memory: "256Mi"
        cpu: "300m"
      limits:
        cpu: "1"
        memory: "512Mi"
    bra:
      requests:
        memory: "1Gi"
        cpu: "500m"
        ephemeral-storage: "10Gi"
      limits:
        cpu: "1"
        memory: "2Gi"
        ephemeral-storage: "12Gi"
  service:
    endpoints:
      postgres:
        tls:
          enforced: required
      postgresExporter:
        tls:
          enforced: optional
  nodeSelector: {}
  tolerations: []
  affinity:
    podAntiAffinity: "soft" # String value, valid values are "soft" or "hard".
  security:
    postgres:
      tls:
        enable: true
    tls:
      brAgent:
        enabled: true

eric-bss-notification-service-database-pg:
  nameOverride: eric-bss-notification-service-database-pg
  enabled: true
  brAgent:
    enabled: true
    logLevel: info
    logicalDBBackupEnable: false
  imageCredentials:
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
    repoPath: eocecm22 # Updated added
    pullPolicy: IfNotPresent
  highAvailability:
    synchronousModeEnabled: true
    replicaCount: 2
  postgresDatabase: "bss-notification-service"
  credentials:
    kubernetesSecretName: "eric-data-document-database-pg-credentials"
    keyForUserId: "notificationUKey"
    keyForUserPw: "notificationPKey"
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
  persistentVolumeClaim:
    storageClassName: gp2
    enabled: true
    size: 8Gi
  patroni:
    logLevel: INFO
  metrics:
    enabled: true
    logLevel: info
    service:
      port: 9187
  resources:
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
    postgres:
      requests:
        memory: "256Mi"
        cpu: "100m"
        hugepages-2Mi:
        hugepages-1Gi:
      limits:
        cpu: "1"
        memory: "2560Mi"
        hugepages-2Mi:
        hugepages-1Gi:
    metrics:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "256Mi"
    kube_client:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "512Mi"
    brm:
      requests:
        memory: "256Mi"
        cpu: "300m"
      limits:
        cpu: "1"
        memory: "512Mi"
    bra:
      requests:
        memory: "1Gi"
        cpu: "500m"
        ephemeral-storage: "10Gi"
      limits:
        cpu: "1"
        memory: "2Gi"
        ephemeral-storage: "12Gi"
  service:
    endpoints:
      postgres:
        tls:
          enforced: optional
      postgresExporter:
        tls:
          enforced: optional
  nodeSelector: {}
  tolerations: []
  affinity:
    podAntiAffinity: "soft" # String value, valid values are "soft" or "hard".
  security:
    postgres:
      tls:
        enable: true
    tls:
      brAgent:
        enabled: true

eric-fm-database-pg:
  nameOverride: eric-fm-database-pg
  enabled: true
  highAvailability:
    replicaCount: 2
    synchronousModeEnabled: true
  imageCredentials:
    pullPolicy: IfNotPresent
    repoPath: eocecm22 # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
  postgresDatabase: "adp_gs_ah"
  persistentVolumeClaim:
    storageClassName: gp2
    enabled: true
    size: 2Gi
  service:
    endpoints:
      postgres:
        tls:
          enforced: required
      postgresExporter:
        tls:
          enforced: optional
  nodeSelector: {}
  tolerations: []
  affinity:
    podAntiAffinity: "soft" # String value, valid values are "soft" or "hard".
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
  credentials:
    kubernetesSecretName: "eric-data-document-database-pg-credentials"
    keyForUserId: "ahUKey"
    keyForUserPw: "ahPKey"
  patroni:
    logLevel: INFO
  security:
    postgres:
      tls:
        enable: true
  metrics:
    enabled: true
    logLevel: info
    service:
      port: 9187
  resources:
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
    postgres:
      requests:
        memory: "256Mi"
        cpu: "100m"
        hugepages-2Mi:
        hugepages-1Gi:
      limits:
        cpu: "1"
        memory: "2560Mi"
        hugepages-2Mi:
        hugepages-1Gi:
    metrics:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "256Mi"
    kube_client:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "512Mi"
    brm:
      requests:
        memory: "256Mi"
        cpu: "300m"
      limits:
        cpu: "1"
        memory: "512Mi"
    bra:
      requests:
        memory: "1Gi"
        cpu: "500m"
        ephemeral-storage: "10Gi"
      limits:
        cpu: "1"
        memory: "2Gi"
        ephemeral-storage: "12Gi"

eric-cm-database-pg:
  nameOverride: eric-data-document-database-pg
  enabled: true
  # global:
  #   security:
  #     tls:
  #       enabled: true
  highAvailability:
    replicaCount: 2
    synchronousModeEnabled: true
  imageCredentials:
    pullPolicy: IfNotPresent
    repoPath: eocecm22 # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
  postgresDatabase: "adp_gs_cm"
  persistentVolumeClaim:
    storageClassName: gp2
    enabled: true
    size: 2Gi
  service:
    endpoints:
      postgres:
        tls:
          enforced: required
      postgresExporter:
        tls:
          enforced: optional
  nodeSelector: {}
  tolerations: []
  affinity:
    podAntiAffinity: "soft" # String value, valid values are "soft" or "hard".
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
  credentials:
    kubernetesSecretName: "eric-data-document-database-pg-credentials"
    keyForUserId: "cmmUKey"
    keyForUserPw: "cmmPKey"
  patroni:
    logLevel: INFO
  security:
    postgres:
      tls:
        enable: true # For cm-mediator 6.0.0, the certificate generated by global.security.tls is used.
  metrics:
    enabled: true
    logLevel: info
    service:
      port: 9187
  brAgent:
    enabled: true
    logicalDBBackupEnable: false
    backupTypeList:
      - "configuration-data"
    logLevel: info
  resources:
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
    postgres:
      requests:
        memory: "256Mi"
        cpu: "100m"
        hugepages-2Mi:
        hugepages-1Gi:
      limits:
        cpu: "1"
        memory: "2560Mi"
        hugepages-2Mi:
        hugepages-1Gi:
    metrics:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "256Mi"
    kube_client:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "512Mi"
    brm:
      requests:
        memory: "256Mi"
        cpu: "300m"
      limits:
        cpu: "1"
        memory: "512Mi"
    bra:
      requests:
        memory: "1Gi"
        cpu: "500m"
        ephemeral-storage: "10Gi"
      limits:
        cpu: "1"
        memory: "2Gi"
        ephemeral-storage: "12Gi"

eric-ctrl-bro:
  enabled: true
  imageCredentials: # Updated added
    pullSecret: scmcred # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
    repoPath: eocecm22 # Updated added
  global:
    setFsGroup: true
  bro:
    enableNotifications: true
  kafka:
    hostname: eric-data-message-bus-kf-client
    port: 9092
  persistence:
    persistentVolumeClaim:
      storageClassName: gp2
      size: 5Gi
  resources:
    backupAndRestore:
      limits:
        cpu: "2"
        memory: "4Gi"
        ephemeral-storage: "250Mi"
      requests:
        cpu: "1"
        memory: "2Gi"
        ephemeral-storage: "100Mi"
  security:
    tls:
      broToAgent:
        enabled: true
      rest:
        enabled: false

eric-sec-access-mgmt:
  enabled: true
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  imageCredentials:
    repoPath: eocecm22 # Updated added
    pullPolicy: IfNotPresent
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
      pullSecret: scmcred # Updated added
  statefulset:
    adminSecret: eric-sec-access-mgmt-creds
    userkey: kcadminid
    passwdkey: kcpasswd
  service:
    tls:
      enabled: true
  global:
    security:
      tls:
        enabled: true
  tls:
    client:
      pg:
        ## The issuer must match the issuer named by PG chart. The general format
        ## [chart-name]-client-ca. Change the value when PG chart is installed with
        ## a different alias, accordingly.
        issuer: eric-idam-database-pg-client-ca
        ## The PG database user name must be the subject of client certificate
        ## if the user does not exist it will be created automatically
        subject: "pguser"
        mountPath: "/run/secrets/pg-client-certificate"
  ingress:
    enabled: true
    hostname: eric-sec-access-mgmt # Don't change, otherwise RBAC proxy won't work.
    inghostname: a1d5aa05eaaeb4ed1a5baab7b84027f7-c9baa8228601ddde.elb.eu-south-1.amazonaws.com # Update this to create the NGINX Ingress
  persistence:
    dbHost: eric-idam-database-pg
    dbName: idam
    dbUserkey: amUKey
    dbPasswdkey: amPKey
    dbsecret: eric-data-document-database-pg-credentials
    tls:
      enabled: false # If this is true then the pod is not deployed due to a fault in the statefulset.
  resources:
    iam:
      requests:
        cpu: 300m
        memory: 768Mi
      limits:
        cpu: 3000m
        memory: 2036Mi
  metrics:
    enabled: false
  http:
    hostValidation:
      ## Host Validation is always enabled by default. Following hosts are
      ## considered valid by default:
      ## * IAM service DNS
      ## * Ingress hostname
      ## Additinally a comma-separated list of values to be considered valid
      ## for the HTTP `Host` header in requests passed to IAM (during Host
      ## header validation) can be specified below.
      allowedHosts: a1d5aa05eaaeb4ed1a5baab7b84027f7-c9baa8228601ddde.elb.eu-south-1.amazonaws.com  # Updated

eric-data-search-engine-rbac-proxy:
  enabled: false
  nameOverride: eric-data-search-engine-rbac-proxy
  config:
    upstream:
      url: http://eric-data-search-engine:9200
      caSecret:
    certAuth:
      enabled: false
      clientCaSecret:
    oidcAuth:
      enabled: true
      caSecret: eric-sec-sip-tls-trusted-root-cert
      clientId: AuthorizationClient
      issuerUrl: https://eric-sec-access-mgmt/auth/realms/master
      usernameClaim: email
      groupsClaim: groups
    verbose: false
  ingress:
    enabled: true
    fqdn:

eric-fh-alarm-handler-rbac-proxy:
  enabled: false
  nameOverride: eric-fh-alarm-handler-rbac-proxy
  config:
    upstream:
      url: http://eric-fh-alarm-handler:5005
      caSecret:
    certAuth:
      enabled: false
      clientCaSecret:
    oidcAuth:
      enabled: true
      caSecret: eric-sec-sip-tls-trusted-root-cert
      clientId: AuthorizationClient
      issuerUrl: https://eric-sec-access-mgmt/auth/realms/master
      usernameClaim: email
      groupsClaim: groups
    verbose: false
  ingress:
    enabled: true
    fqdn:

eric-pm-server-rbac-proxy:
  enabled: false
  nameOverride: eric-pm-server-rbac-proxy
  config:
    upstream:
      url: http://eric-pm-server:9090
      caSecret:
    certAuth:
      enabled: false
      clientCaSecret:
    oidcAuth:
      enabled: true
      caSecret: eric-sec-sip-tls-trusted-root-cert
      clientId: AuthorizationClient
      issuerUrl: https://eric-sec-access-mgmt/auth/realms/master
      usernameClaim: email
      groupsClaim: groups
    verbose: false
  ingress:
    enabled: true
    fqdn:

eric-cm-mediator-rbac-proxy:
  enabled: true
  nameOverride: eric-cm-mediator-rbac-proxy
  config:
    upstream:
      url: https://eric-cm-mediator:5004
      caSecret: eric-sec-sip-tls-trusted-root-cert
    certAuth:
      enabled: false
      clientCaSecret:
    oidcAuth:
      enabled: true
      caSecret: eric-sec-sip-tls-trusted-root-cert
      clientId: AuthorizationClient
      issuerUrl: https://eric-sec-access-mgmt/auth/realms/master
      usernameClaim: email
      groupsClaim: groups
    verbose: false
  ingress:
    enabled: true
    fqdn:

eric-pm-bulk-reporter:
  enabled: false
  imageCredentials: # Updated added
    repoPath: "eocecm22" # Updated added
    pullPolicy: IfNotPresent # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
  userConfig:
    secretName: pm-br-sftp-users-secret
    secretKey: users.yaml
  resources:
    initcontainer:
      requests:
        cpu: "50m"
        memory: "50Mi"
      limits:
        cpu: "1"
        memory: "200Mi"
    bulkreporter:
      requests:
        cpu: "100m"
        memory: "50Mi"
        ephemeral-storage: 50Mi
      limits:
        cpu: "1"
        memory: "200Mi"
        ephemeral-storage: 500Mi
    alarmreporter:
      requests:
        cpu: "100m"
        memory: "50Mi"
        ephemeral-storage: 50Mi
      limits:
        cpu: "1"
        memory: "200Mi"
        ephemeral-storage: 500Mi
    pmsftp:
      requests:
        cpu: "50m"
        memory: "50Mi"
        ephemeral-storage: 50Mi
      limits:
        cpu: "1"
        memory: "200Mi"
        ephemeral-storage: 500Mi
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
  thresholdReporter:
    enabled: false
    kafkahost: eric-data-message-bus-kf:9093
    thresholdGps: "ten-seconds thirty-seconds one-min five-min fifteen-min thirty-min one-hour twelve-hour one-day"
  #nodeSelector:


eric-pm-server:
  enabled: true
  server:
    serviceAccountName: eric-pm-server
    persistentVolume:
      enabled: true
      accessModes:
      - ReadWriteOnce
      annotations: {}
      mountPath: "/data"
      size: 8Gi
      storageConnectivity: networked
      subPath: ''
      retention: '15d'
      storageClass: gp2 # Use when storageConnectivity is local
    #replicaCount: 1
  rbac:
    appMonitoring:
      enabled: true
      configFileCreate: false
  resources:
    eric-pm-server:
      limits:
        cpu: "2"
        memory: "2048Mi"
      requests:
        cpu: "250m"
        memory: "512Mi"
    eric-pm-configmap-reload:
      limits:
        cpu: "200m"
        memory: "32Mi"
      requests:
        cpu: "100m"
        memory: "8Mi"
    eric-pm-exporter:
      limits:
        cpu: "200m"
        memory: "32Mi"
      requests:
        cpu: "100m"
        memory: "8Mi"
    eric-pm-reverseproxy:
      limits:
        cpu: "2"
        memory: "128Mi"
      requests:
        cpu: "100m"
        memory: "32Mi"
    logshipper:
      limits:
        cpu: "100m"
        memory: "50Mi"
      requests:
        cpu: "50m"
        memory: "25Mi"
  imageCredentials: # Updated
    repoPath: "eocecm22" # Updated
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com
  service:
    endpoints:
      reverseproxy:
        tls:
          verifyClientCertificate: optional
  serverFiles:
    prometheus.yml: |
      global:
        scrape_interval: 15s
        scrape_timeout: 10s
        evaluation_interval: 1m
      rule_files:
        - wcdbcd-rules.yml
        - kafkaMetrics-rules.yml
      scrape_configs:
        - job_name: prometheus
          static_configs:
            - targets:
              - localhost:9090
              - localhost:9087

        - job_name: 'kubernetes-nodes'

          # Default to scraping over https. If required, just disable this or change to
          # `http`.
          scheme: https

          # This TLS & bearer token file config is used to connect to the actual scrape
          # endpoints for cluster components. This is separate to discovery auth
          # configuration because discovery & scraping are two separate concerns in
          # Prometheus. The discovery auth config is automatic if Prometheus runs inside
          # the cluster. Otherwise, more config options have to be provided within the
          # <kubernetes_sd_config>.
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            # If your node certificates are self-signed or use a different CA to the
            # master CA, then disable certificate verification below. Note that
            # certificate verification is an integral part of a secure infrastructure
            # so this should only be disabled in a controlled environment. You can
            # disable certificate verification by uncommenting the line below.
            #
            #insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

          kubernetes_sd_configs:
            - role: node

          relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)
            - target_label: __address__
              replacement: kubernetes.default.svc:443
            - source_labels: [__meta_kubernetes_node_name]
              regex: (.+)
              target_label: __metrics_path__
              replacement: /api/v1/nodes/${1}/proxy/metrics


        - job_name: 'kubernetes-nodes-cadvisor'

          # Default to scraping over https. If required, just disable this or change to
          # `http`.
          scheme: https

          # This TLS & bearer token file config is used to connect to the actual scrape
          # endpoints for cluster components. This is separate to discovery auth
          # configuration because discovery & scraping are two separate concerns in
          # Prometheus. The discovery auth config is automatic if Prometheus runs inside
          # the cluster. Otherwise, more config options have to be provided within the
          # <kubernetes_sd_config>.
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            # If your node certificates are self-signed or use a different CA to the
            # master CA, then disable certificate verification below. Note that
            # certificate verification is an integral part of a secure infrastructure
            # so this should only be disabled in a controlled environment. You can
            # disable certificate verification by uncommenting the line below.
            #
            #insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

          kubernetes_sd_configs:
            - role: node

          # This configuration will work only on kubelet 1.7.3+
          # As the scrape endpoints for cAdvisor have changed
          # if you are using older version you need to change the replacement to
          # replacement: /api/v1/nodes/${1}:4194/proxy/metrics
          relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)
            - target_label: __address__
              replacement: kubernetes.default.svc:443
            - source_labels: [__meta_kubernetes_node_name]
              regex: (.+)
              target_label: __metrics_path__
              replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

        # Scrape config for service endpoints.
        #
        # The relabeling allows the actual service scrape endpoint to be configured
        # via the following annotations:
        #
        # * `prometheus.io/scrape`: Only scrape services that have a value of `true`
        # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
        # to set this to `https` & most likely set the `tls_config` of the scrape config.
        # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
        # * `prometheus.io/port`: If the metrics are exposed on a different port to the
        # service then set this appropriately.
        - job_name: 'kubernetes-service-endpoints'

          kubernetes_sd_configs:
            - role: endpoints

          tls_config:
            ca_file: /run/secrets/cacert/ca.crt

          relabel_configs:
            - source_labels: [__meta_kubernetes_service_name]
              action: replace
              target_label: job
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
              action: keep
              regex: true
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
              action: replace
              target_label: __scheme__
              regex: (https?)
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
              action: replace
              target_label: __metrics_path__
              regex: (.+)
            - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_service_annotation_prometheus_io_port]
              action: replace
              target_label: __address__
              regex: ((?:\[.+\])|(?:.+))(?::\d+);(\d+)
              replacement: $1:$2
            - action: labelmap
              regex: __meta_kubernetes_service_label_(.+)
            - source_labels: [__meta_kubernetes_namespace]
              action: replace
              target_label: kubernetes_namespace
            - source_labels: [__meta_kubernetes_service_name]
              action: replace
              target_label: kubernetes_name
            - source_labels: [__meta_kubernetes_pod_name]
              action: replace
              target_label: kubernetes_pod_name
            - source_labels: [__meta_kubernetes_pod_node_name]
              action: replace
              target_label: kubernetes_pod_node_name

        # Example scrape config for probing services via the Blackbox Exporter.
        #
        # The relabeling allows the actual service scrape endpoint to be configured
        # via the following annotations:
        #
        # * `prometheus.io/probe`: Only probe services that have a value of `true`
        - job_name: 'kubernetes-services'

          metrics_path: /probe
          params:
            module: [http_2xx]

          kubernetes_sd_configs:
            - role: service

          relabel_configs:
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
              action: keep
              regex: true
            - source_labels: [__address__]
              target_label: __param_target
            - target_label: __address__
              replacement: blackbox
            - source_labels: [__param_target]
              target_label: instance
            - action: labelmap
              regex: __meta_kubernetes_service_label_(.+)
            - source_labels: [__meta_kubernetes_namespace]
              target_label: kubernetes_namespace
            - source_labels: [__meta_kubernetes_service_name]
              target_label: kubernetes_name

        # Example scrape config for pods
        #
        # The relabeling allows the actual pod scrape endpoint to be configured via the
        # following annotations:
        #
        # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`
        # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
        # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.
        - job_name: 'kubernetes-pods'

          kubernetes_sd_configs:
            - role: pod

          relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              action: keep
              regex: true
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
              action: replace
              target_label: __scheme__
              regex: (https?)
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
              action: replace
              target_label: __metrics_path__
              regex: (.+)
            - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
              action: replace
              regex: ((?:\[.+\])|(?:.+))(?::\d+);(\d+)
              replacement: $1:$2
              target_label: __address__
            - action: labelmap
              regex: __meta_kubernetes_pod_label_(.+)
            - source_labels: [__meta_kubernetes_namespace]
              action: replace
              target_label: kubernetes_namespace
            - source_labels: [__meta_kubernetes_pod_name]
              action: replace
              target_label: kubernetes_pod_name
    wcdbcd-rules.yml: |
      groups:
        - name: wcdbcd
          rules:
            - record: Cassandra_table_compaction_size
              expr: max(cassandra_table_estimated_pending_compactions)
            - record: Cassandra_table_partition_size
              expr: max(cassandra_table_partition_size_maximum_bytes)
            - record: Cassandra_client_request_failure_count
              expr: sum(cassandra_client_request_failures_total)
            - record: Cassandra_request_unavailable
              expr: sum(cassandra_client_request_failures_total)
            - record: wcdbcd_storage_ratio
              expr: (cassandra_storage_filesystem_bytes_total - cassandra_storage_filesystem_usable_bytes) / cassandra_storage_filesystem_bytes_total
            - record: wcdbcd_storage_low_sliding_window_ratio
              expr: (cassandra_storage_filesystem_bytes_total - max_over_time(cassandra_storage_filesystem_usable_bytes[30m])) / cassandra_storage_filesystem_bytes_total
            - record: Cassandra_unresponsive_nodes
              expr: max(count(cassandra_endpoint_active) by (endpoint)) - min(sum(cassandra_endpoint_active) by (cassandra_node))
            - record: Cassandra_write_latency
              expr: max(cassandra_client_request_latency_seconds{quantile="0.99", operation="write"})
            - record: Cassandra_read_latency
              expr: max(cassandra_client_request_latency_seconds{quantile="0.99", operation="read"})
            - record: Cassandra_clinet_request_timeout
              expr: sum(cassandra_client_request_timeouts_total)
            - record: Cassandra_table_live_sstable_count
              expr: max(cassandra_table_live_sstables)
            - record: Cassandra_table_sstable_per_read_count
              expr: max(cassandra_table_sstables_per_read)
    kafkaMetrics-rules.yml: |
      groups:
        - name: kafkaMetrics
          rules:
            - record: kafka_cpu_usages
              expr: sum(rate(container_cpu_usage_seconds_total{name=~".*message-bus-kf.*", image!="", container!="POD"}[10m])) by (pod, container) / sum(container_spec_cpu_quota{name=~".*message-bus-kf.*", image!="", container!="POD"}/container_spec_cpu_period{name=~".*message-bus-kf.*", image!="", container!="POD"}) by (pod, container)
            - record: kafka_memory_usage
              expr: rate(java_lang_OperatingSystem_FreePhysicalMemorySize{kubernetes_pod_name=~".*message-bus-kf.*"}[5m]) / java_lang_OperatingSystem_TotalPhysicalMemorySize{kubernetes_pod_name=~".*message-bus-kf.*"}
            - record: kafka_disk_usage
              expr: (kubelet_volume_stats_capacity_bytes {persistentvolumeclaim=~".*message-bus-kf.*"} - kubelet_volume_stats_available_bytes{persistentvolumeclaim=~".*message-bus-kf.*"}) / kubelet_volume_stats_capacity_bytes {persistentvolumeclaim=~".*message-bus-kf.*"} * 100
            - record: kafka_produce_processing_time
              expr: max(kafka_network_RequestMetrics_99thPercentile{name="TotalTimeMs", request="Produce"})
            - record: kafka_fetch_processing_time
              expr: max(kafka_network_RequestMetrics_99thPercentile{name="TotalTimeMs", request="Fetch"})
            - record: kafka_fetchConsumer_processing_time
              expr: max(kafka_network_RequestMetrics_99thPercentile{name="TotalTimeMs", request="FetchConsumer"})
            - record: kafka_failure_request_count
              expr: sum(kafka_network_RequestMetrics_Count{name="ErrorsPerSec",error!="NONE"})
            - record: kafka_produce_purgatory_size
              expr: Max(kafka_server_DelayedOperationPurgatory_Value{name="PurgatorySize",delayedOperation="Produce"})
            - record: kafka_fetch_purgatory_size
              expr: Max(kafka_server_DelayedOperationPurgatory_Value{name="PurgatorySize",delayedOperation="Fetch"})
            - record: kafka_replicated_partition_size
              expr: sum(kafka_server_ReplicaManager_Value{name="UnderReplicatedPartitions"})
            - record: kafka_partition_without_leader
              expr: sum(kafka_controller_KafkaController_Value{name="OfflinePartitionsCount"})
            - record: kafka_leader_election_rate
              expr: sum(kafka_controller_ControllerStats_50thPercentile{name="LeaderElectionRateAndTimeMs"})
            - record: kafka_active_controller_count
              expr: sum(kafka_controller_KafkaController_Value{name="ActiveControllerCount"})
            - record: kafka_unclean_leader_election_rate
              expr: sum(kafka_controller_ControllerStats_FiveMinuteRate{name="UncleanLeaderElectionsPerSec"})
            - record: kafka_max_lag_between_leader_and_follower
              expr: kafka_server_ReplicaFetcherManager_Value{app="eric-data-message-bus-kf",name="MaxLag"}
  #nodeSelector:

eric-tm-ingress-controller-cr-crd:
  enabled: false

eric-lcm-container-registry:
  enabled: false
  registry:
    users:
      secret: eric-lcm-container-registry

eric-lcm-helm-chart-registry:
  enabled: false

eric-bss-kafka-proxy:
  enabled: false

eric-nels-database-pg:
  nameOverride: eric-nels-database-pg
  enabled: true
  # global:
  #   security:
  #     tls:
  #       enabled: false
  imageCredentials: # Updated added
    repoPath: "eocecm22" # Updated added
    pullPolicy: IfNotPresent # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
  highAvailability:
    synchronousModeEnabled: true
    replicaCount: 1
  postgresDatabase: "licensemanager_db"
  credentials:
    kubernetesSecretName: "eric-data-document-database-pg-credentials"
    keyForUserId: "nelsUKey"
    keyForUserPw: "nelsPKey"
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
  persistentVolumeClaim:
    storageClassName: gp2
    enabled: true
    size: 8Gi
  patroni:
    logLevel: INFO
  metrics:
    enabled: true
    logLevel: info
    service:
      port: 9187
  resources:
    logshipper:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "100Mi"
        cpu: "100m"
    postgres:
      requests:
        memory: "256Mi"
        cpu: "100m"
        hugepages-2Mi:
        hugepages-1Gi:
      limits:
        cpu: "1"
        memory: "2560Mi"
        hugepages-2Mi:
        hugepages-1Gi:
    metrics:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "256Mi"
    kube_client:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        cpu: "200m"
        memory: "512Mi"
    brm:
      requests:
        memory: "256Mi"
        cpu: "300m"
      limits:
        cpu: "1"
        memory: "512Mi"
    bra:
      requests:
        memory: "1Gi"
        cpu: "500m"
        ephemeral-storage: "10Gi"
      limits:
        cpu: "1"
        memory: "2Gi"
        ephemeral-storage: "12Gi"
  service:
    endpoints:
      postgres:
        tls:
          enforced: required
      postgresExporter:
        tls:
          enforced: optional
  nodeSelector: {}
  tolerations: []
  affinity:
    podAntiAffinity: "soft" # String value, valid values are "soft" or "hard".
  security:
    postgres:
      tls:
        enable: true

eric-lm-combined-server:
  nameOverride: eric-lm-combined-server
  enabled: true
  imageCredentials: # Updated added
    repoPath: "eocecm22" # Updated added
    pullPolicy: IfNotPresent # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
  # Mandatory: global.ericsson.licensing.licenseDomains - The licensing domain information for
  # each product type used by ADP LM, formatted as entries in an array like so:
  #  - productType: <product type>
  #    swltId: <software license target ID>
  #    customerId: <customer Id>
  global:
    ericsson:
      licensing:
        licenseDomains:
          - productType: CATALOG_MANAGER # ECM
            swltId: STB-CATALOG_MANAGER-1
            customerId: 800141
          - productType: ORDER_CARE # EOC
            swltId: STB-ORDER_CARE-1
            customerId: 800141
    # security:
    #   tls:
    #     enabled: false
  licenseServerClient:
    licenseServer:
      thrift:
        host: 10.221.14.90 # Central Nels Server
  database:
    credentials:
      secretName: eric-data-document-database-pg-credentials
      userKey: nelsUKey
      passwordKey: nelsPKey
    host: eric-nels-database-pg
    # tls:
    #   enforced: optional
  tls:
    lch:
      # tls.lch.certTtl - The duration (seconds) that the certificate is valid, range 180 - 315576000
      certTtl: 15778800

eric-data-object-storage-mn:
  enabled: false
  imageCredentials: # Updated added
    repoPath: "eocecm22" # Updated added
    pullPolicy: IfNotPresent # Updated added
    registry: # Updated added
      url: 268558760722.dkr.ecr.eu-south-1.amazonaws.com # Updated added
  ## set kubernetes cluster domain where object-storage service is running
  ##
  clusterDomain: cluster.local

  ## distributed  vs standalone
  ##
  mode: distributed

  ## Pod priority settings
  ##
  priorityClassName: ""

  ## Mandatory parameters
  ## Credentials to access storage service, a standard k8s secret, with data: accesskey and secretkey.
  credentials:
    kubernetesSecretName: "object-storage-secret"
    accesskey: "TESTPKEY"
    secretkey: "TESTPKEY"

  ## Set default Minio volume mount path and number of nodes (only used for Minio distributed mode)
  ##
  mountPath: "/export"
  replicas: 4

  ## TLS Settings for Minio
  tls:
    ## Given secret with publicCrt and privateKey files and pass that here as service certificate.
    ## Otherwise SIP-TLS auto-generates a service certificate as default if certSecret "".
    certSecret: ""
    publicCrt: public.crt
    privateKey: private.key
    # Root CA for connecting Object Storage by HTTPS
    caSecret: "eric-sec-sip-tls-trusted-root-cert"
    caCert: "cacertbundle.pem"


  ## Object Storage Data Scurity, auto Encryption/Decryption Setting
  ## Object Storage sevice ensures all uploaded objects are encrypted using specified KMS configuration.
  ## It only supports approle authentication type to login KMS. And tls enable is mandatory.
  ##
  autoEncryption:
    enabled: true
    kmsConfigSecret: eric-data-object-storage-mn-kms-set

  ## Persistent storage attributes (mandatory parameters)
  ##
  ##  Object storage pods use local storage if storageConnectivity set as "local".
  ##  Because local volumes do not currently support dynamic provisioning, this
  ##  requires system administrator to prepare,
  ##    1. Specified StorageClass to delay volume binding until pod scheduling.
  ##    2. PersistentVolume with spec.storageClassName as "local storage" per worker node.
  ##  Note:
  ##    The number of worker node must be equal or large than replicas number in distributed mode.
  ##    And, guarantee the node in health state so that the pod can be scheduled on that node.

  persistentVolumeClaim:
    # The storage class name for persistent volume,
    storageClassName: "gp2"
    # The connectivity of the storage, either local or networked, networked is default
    storageConnectivity: local
    #size of each pvc
    size: 10Gi
    #pvc name format: [volumeNamePrefix-]helmRelease-ChartName
    volumeNamePrefix: export
    # If subPath is set mount a sub folder of a volume instead of the root of the volume.
    subPath: ""

  ## Custom Ingess to access Minio presigned URL from Web application
  ingress:
      enabled: true
      annotations:
        kubernetes.io/ingress.class: nginx
        nginx.ingress.kubernetes.io/backend-protocol: HTTPS
        nginx.ingress.kubernetes.io/proxy-body-size: 20m
        nginx.ingress.kubernetes.io/proxy-connect-timeout: "180"
        nginx.ingress.kubernetes.io/proxy-read-timeout: "180"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "180"
        nginx.ingress.kubernetes.io/upstream-vhost: eric-data-object-storage-mn:9000
        nginx.ingress.kubernetes.io/use-regex: "true"
        nginx.ingress.kubernetes.io/rewrite-target: /$1
      hosts:
        - host: ingress-nginx
          paths:
          - /
      tls:
        - secretName: extingresscerts
          hosts:
          - ingress-nginx
